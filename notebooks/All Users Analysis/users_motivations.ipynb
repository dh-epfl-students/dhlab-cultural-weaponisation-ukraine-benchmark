{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "038e793d-e023-4fa7-a1bf-b50ca82cabfb",
   "metadata": {},
   "source": [
    "# Users motivations\n",
    "\n",
    "Finally, to give some insights about the why question, I did a manual analysis of the top 12 most contributors as well as people that have more weaponising edits than not weaponising edits. The manual analysis is based on the User page and the User talk page mainly. We are seeking banners, templates and semantic behaviour that tells a lot about someone’s identity, ideology and culture. However, those features can give some insights and some potential \n",
    "direction but we cannot and we won’t determine someone's culture only based on his wikipedia page. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9e1f4c-edb3-44d7-bc95-356fff7fb4db",
   "metadata": {},
   "source": [
    "## Templates analysis\n",
    "\n",
    "This section is a depp analysis into the users template banner used. Templates are very often used by user as : \n",
    "* identity markers\n",
    "* ideological broadcasting\n",
    "* group affiliations signals\n",
    "* defensive framings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ae3797-aad4-450e-9baa-0cd422c127f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import mwparserfromhell\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"DH_Project/1.0 (https://www.epfl.ch/labs/dhlab/; maxime.garambois@epfl.ch)\"\n",
    "}\n",
    "\n",
    "SLEEP_TIME = 0.5  # be polite to the API\n",
    "\n",
    "\n",
    "def fetch_wikitext(title):\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"prop\": \"revisions\",\n",
    "        \"rvprop\": \"content\",\n",
    "        \"rvslots\": \"main\",\n",
    "        \"titles\": title,\n",
    "        \"format\": \"json\",\n",
    "        \"formatversion\": \"2\"\n",
    "    }\n",
    "\n",
    "    r = requests.get(URL, params=params, headers=HEADERS)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    pages = data.get(\"query\", {}).get(\"pages\", [])\n",
    "    if not pages or \"missing\" in pages[0]:\n",
    "        return None\n",
    "\n",
    "    revisions = pages[0].get(\"revisions\", [])\n",
    "    if not revisions:\n",
    "        return None\n",
    "\n",
    "    return revisions[0][\"slots\"][\"main\"][\"content\"]\n",
    "\n",
    "\n",
    "def extract_templates(wikitext):\n",
    "    wikicode = mwparserfromhell.parse(wikitext)\n",
    "    templates = []\n",
    "\n",
    "    for tpl in wikicode.filter_templates(recursive=True):\n",
    "        templates.append({\n",
    "            \"template_name\": str(tpl.name).strip(),\n",
    "            \"parameters\": {\n",
    "                str(param.name).strip(): str(param.value).strip()\n",
    "                for param in tpl.params\n",
    "            }\n",
    "        })\n",
    "\n",
    "    return templates\n",
    "\n",
    "\n",
    "def process_user(username):\n",
    "    results = []\n",
    "\n",
    "    for page_type, title in [\n",
    "        (\"user\", f\"User:{username}\"),\n",
    "        (\"user_talk\", f\"User talk:{username}\")\n",
    "    ]:\n",
    "        try:\n",
    "            wikitext = fetch_wikitext(title)\n",
    "            if not wikitext:\n",
    "                continue\n",
    "\n",
    "            templates = extract_templates(wikitext)\n",
    "\n",
    "            for tpl in templates:\n",
    "                results.append({\n",
    "                    \"username\": username,\n",
    "                    \"page_type\": page_type,\n",
    "                    \"template_name\": tpl[\"template_name\"],\n",
    "                    \"parameters\": tpl[\"parameters\"]\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {username} ({page_type}): {e}\")\n",
    "\n",
    "        time.sleep(SLEEP_TIME)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def run():\n",
    "    all_results = []\n",
    "\n",
    "    for user in tqdm(top10_users, desc=\"Processing users\"):\n",
    "        all_results.extend(process_user(user))\n",
    "\n",
    "    # Save JSON (full fidelity)\n",
    "    with open(\"user_templates_raw.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # Save CSV (easy inspection)\n",
    "    with open(\"user_templates_raw.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(\n",
    "            f,\n",
    "            fieldnames=[\"username\", \"page_type\", \"template_name\", \"parameters\"]\n",
    "        )\n",
    "        writer.writeheader()\n",
    "        for row in all_results:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(\"✔ Extraction complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac5558d-25b0-4acf-89ca-7e7097b1acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_templates = pd.read_csv('user_templates_raw.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADA Env",
   "language": "python",
   "name": "ada"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
