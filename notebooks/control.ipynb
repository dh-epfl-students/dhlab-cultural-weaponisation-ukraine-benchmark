{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f715b039-b777-417b-b581-7598ef2fe40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import difflib\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f4b9b90c-88fb-483b-8597-bfb6a1cef04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_articles = [\n",
    "    \"Pop music\",\n",
    "    \"Rock and roll\",\n",
    "    \"Eric Clapton\",\n",
    "    \"Rolling Stone\",\n",
    "    \"Jazz\",\n",
    "    \"Swing\",\n",
    "    \"Classical music\",\n",
    "    \"Ludwig van Beethoven\",\n",
    "    \"Wolfgang Amadeus Mozart\",\n",
    "    \"Joseph Haydn\",\n",
    "    \"Country music\",\n",
    "    \"BTS (groupe)\",\n",
    "    \"K-Pop\",\n",
    "    \"Electronic music\",\n",
    "    \"Daft Punk\",\n",
    "    \"Paul Kalkbrenner\",\n",
    "    \"Trumpet\",\n",
    "    \"Music theory\",\n",
    "    \"Fender\",\n",
    "    \"Marshall Amplification\",\n",
    "    \"Jimi Hendrix\",\n",
    "    \"Bob Marley\",\n",
    "    \"Edith Piaf\",\n",
    "    \"Royal Albert Hall\",\n",
    "    \"Piano\",\n",
    "    \"Saxophone\",\n",
    "    \"Pink Floyd\",\n",
    "    \"Nirvana (band)\",\n",
    "    \"Nina Simone\",\n",
    "    \"Music of Africa\",\n",
    "    \"Major scale\",\n",
    "    \"Major chord\",\n",
    "    \"Minor chord\",\n",
    "    \"AC/DC\",\n",
    "    \"Red Hot Chili Peppers\",\n",
    "    \"Funk rock\",\n",
    "    \"James Brown\",\n",
    "    \"Dire Straits\",\n",
    "    \"Mark Knofler\",\n",
    "    \"John Frusciante\",\n",
    "    \"Alan Clark\",\n",
    "    \"Bob Dylan\",\n",
    "    \"The Beatles\",\n",
    "    \"Stevie Wonder\",\n",
    "    \"Guitar\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b4169e1c-aac8-4546-a0b8-861d007ccfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:   0%|                               | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching revisions for: Pop music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:   0%|                               | 0/45 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[131]\u001b[39m\u001b[32m, line 126\u001b[39m\n\u001b[32m    122\u001b[39m                 out_f.write(json.dumps(rec, ensure_ascii=\u001b[38;5;28;01mFalse\u001b[39;00m) + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    124\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m✅ All diffs saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPUT_FILE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[131]\u001b[39m\u001b[32m, line 112\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m title \u001b[38;5;129;01min\u001b[39;00m tqdm(control_articles, desc=\u001b[33m\"\u001b[39m\u001b[33mProcessing articles\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    111\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFetching revisions for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     revisions = \u001b[43mfetch_revisions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  → Retrieved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(revisions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m revisions\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(revisions) < \u001b[32m2\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[131]\u001b[39m\u001b[32m, line 53\u001b[39m, in \u001b[36mfetch_revisions\u001b[39m\u001b[34m(title)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcontinue\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[32m     52\u001b[39m     cont = data[\u001b[33m\"\u001b[39m\u001b[33mcontinue\u001b[39m\u001b[33m\"\u001b[39m]  \u001b[38;5;66;03m# ✅ use the full continuation object\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     time.sleep(SLEEP_BETWEEN)\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import difflib\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import quote\n",
    "\n",
    "WIKI_API = \"https://en.wikipedia.org/w/api.php\"\n",
    "USER_AGENT = \"DH_Project/1.0 (https://www.epfl.ch/labs/dhlab/; maxime.garambois@epfl.ch)\"\n",
    "SLEEP_BETWEEN = 0.5  # seconds\n",
    "OUTPUT_FILE = \"../datas/interim/Control Analysis/control_group_diffs.jsonl\"\n",
    "\n",
    "# ----------------------------------------\n",
    "# STEP 1: Fetch all revisions for an article\n",
    "# ----------------------------------------\n",
    "def fetch_revisions(title):\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\"User-Agent\": USER_AGENT})\n",
    "\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"prop\": \"revisions\",\n",
    "        \"titles\": title,\n",
    "        \"rvprop\": \"ids|timestamp|user|comment|content|parentid\",\n",
    "        \"rvslots\": \"main\",\n",
    "        \"rvlimit\": \"500\",\n",
    "        \"rvdir\": \"newer\",\n",
    "        \"formatversion\": \"2\"\n",
    "    }\n",
    "\n",
    "    all_revs = []\n",
    "    cont = {}\n",
    "    loop = 0\n",
    "\n",
    "    while True:\n",
    "        loop += 1\n",
    "        resp = session.get(WIKI_API, params={**params, **cont}, timeout=60)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "\n",
    "        page = data.get(\"query\", {}).get(\"pages\", [{}])[0]\n",
    "        revs = page.get(\"revisions\", []) or []\n",
    "        for r in revs:\n",
    "            if \"slots\" in r and \"main\" in r[\"slots\"]:\n",
    "                r[\"content\"] = r[\"slots\"][\"main\"].get(\"content\", \"\")\n",
    "            else:\n",
    "                r[\"content\"] = \"\"\n",
    "        all_revs.extend(revs)\n",
    "\n",
    "        if \"continue\" in data:\n",
    "            cont = data[\"continue\"]  # ✅ use the full continuation object\n",
    "            time.sleep(SLEEP_BETWEEN)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    all_revs.sort(key=lambda r: (r[\"timestamp\"], r[\"revid\"]))\n",
    "    print(f\"✅ {title}: fetched {len(all_revs)} revisions across {loop} loops\")\n",
    "    return all_revs\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# STEP 2: Compute diffs between successive revisions\n",
    "# ----------------------------------------\n",
    "def compute_diffs(title, revisions):\n",
    "    \"\"\"\n",
    "    Compute unified diffs between successive revisions.\n",
    "    Returns a list of dicts representing edit events.\n",
    "    \"\"\"\n",
    "    edit_records = []\n",
    "\n",
    "    for i in range(1, len(revisions)):\n",
    "        prev_rev = revisions[i - 1]\n",
    "        curr_rev = revisions[i]\n",
    "\n",
    "        before = prev_rev[\"content\"]\n",
    "        after = curr_rev[\"content\"]\n",
    "\n",
    "        diff = list(\n",
    "            difflib.unified_diff(\n",
    "                before.splitlines(),\n",
    "                after.splitlines(),\n",
    "                fromfile=f\"{title}@{prev_rev['revid']}\",\n",
    "                tofile=f\"{title}@{curr_rev['revid']}\",\n",
    "                lineterm=\"\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        edit_records.append({\n",
    "            \"article_title\": title,\n",
    "            \"prev_rev_id\": prev_rev[\"revid\"],\n",
    "            \"curr_rev_id\": curr_rev[\"revid\"],\n",
    "            \"timestamp\": curr_rev[\"timestamp\"],\n",
    "            \"user\": curr_rev.get(\"user\", \"(unknown)\"),\n",
    "            \"comment\": curr_rev.get(\"comment\", \"\"),\n",
    "            \"diff_chunks\": diff,\n",
    "            \"pre_edit_text\": before,\n",
    "            \"post_edit_text\": after\n",
    "        })\n",
    "\n",
    "    return edit_records\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# STEP 3: Main pipeline\n",
    "# ----------------------------------------\n",
    "def main():\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as out_f:\n",
    "        for title in tqdm(control_articles, desc=\"Processing articles\"):\n",
    "            print(f\"\\nFetching revisions for: {title}\")\n",
    "            revisions = fetch_revisions(title)\n",
    "            print(f\"  → Retrieved {len(revisions)} revisions\")\n",
    "\n",
    "            if len(revisions) < 2:\n",
    "                continue  # nothing to diff\n",
    "\n",
    "            diffs = compute_diffs(title, revisions)\n",
    "            print(f\"  → Computed {len(diffs)} edit diffs\")\n",
    "\n",
    "            for rec in diffs:\n",
    "                out_f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(f\"\\n✅ All diffs saved to {OUTPUT_FILE}\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b968f19-f417-4f4c-8a8b-1a48aa38abd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADA Env",
   "language": "python",
   "name": "ada"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
