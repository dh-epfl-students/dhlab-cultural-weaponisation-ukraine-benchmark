{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f06c6d5-932c-43e6-a8a0-0290eb61475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root to Python's module search path\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8027d10-1729-436d-92d7-47cea2eb5779",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_folder = Path(\"../datas/raw/LLM_Results\")\n",
    "dfs = [pd.read_csv(f) for f in csv_folder.glob(\"*.csv\")]\n",
    "dfs_named = {f.stem: pd.read_csv(f) for f in csv_folder.glob(\"*.csv\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47f19b77-d77d-4f96-b2eb-09ad0a4a568a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_version</th>\n",
       "      <th>changed_version</th>\n",
       "      <th>comment</th>\n",
       "      <th>user</th>\n",
       "      <th>date</th>\n",
       "      <th>llm_output</th>\n",
       "      <th>weaponised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#REDIRECT [[List of numbers of people immigrat...</td>\n",
       "      <td>Initial revision</td>\n",
       "      <td>Amitchell125 moved page [[Immigration to Ukrai...</td>\n",
       "      <td>Amitchell125</td>\n",
       "      <td>2023-12-30T13:06:33Z</td>\n",
       "      <td>Change: Moved page [[Immigration to Ukraine]] ...</td>\n",
       "      <td>Not Weaponised</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     initial_version   changed_version  \\\n",
       "0  #REDIRECT [[List of numbers of people immigrat...  Initial revision   \n",
       "\n",
       "                                             comment          user  \\\n",
       "0  Amitchell125 moved page [[Immigration to Ukrai...  Amitchell125   \n",
       "\n",
       "                   date                                         llm_output  \\\n",
       "0  2023-12-30T13:06:33Z  Change: Moved page [[Immigration to Ukraine]] ...   \n",
       "\n",
       "       weaponised  \n",
       "0  Not Weaponised  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_named['Immigration_to_Ukraine_analysis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17dfdf1c-00a1-48e2-b3d5-7d46b8c0e549",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_weaponised = [df[df['weaponised'] == 'Weaponised'].reset_index(drop=True) for df in dfs]\n",
    "dfs_weaponised = [df for df in dfs_weaponised if not df.empty]\n",
    "dfs_weaponised_named = {\n",
    "    name: df[df['weaponised'] == 'Weaponised'].reset_index(drop=True)\n",
    "    for name, df in dfs_named.items()\n",
    "    if not df[df['weaponised'] == 'Weaponised'].empty\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8fc417b-d0c2-469a-862e-db4465410381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_version</th>\n",
       "      <th>changed_version</th>\n",
       "      <th>comment</th>\n",
       "      <th>user</th>\n",
       "      <th>date</th>\n",
       "      <th>llm_output</th>\n",
       "      <th>weaponised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{{main|2020 coronavirus outbreak in Europe}}\\n...</td>\n",
       "      <td>--- \\n+++ \\n@@ -26,7 +26,7 @@\\n On 3 March, Uk...</td>\n",
       "      <td>cite web</td>\n",
       "      <td>VanHelsing.16</td>\n",
       "      <td>2020-03-13T14:04:15Z</td>\n",
       "      <td>Change: Replaced a URL reference with a citati...</td>\n",
       "      <td>Weaponised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{{main|2020 coronavirus outbreak in Europe}}\\n...</td>\n",
       "      <td>--- \\n+++ \\n@@ -17,18 +17,17 @@\\n The [[2019‚Äì2...</td>\n",
       "      <td>/* Timeline */ copyediting - millions of Ukrai...</td>\n",
       "      <td>Boud</td>\n",
       "      <td>2020-03-16T02:16:56Z</td>\n",
       "      <td>The change made in this revision is the replac...</td>\n",
       "      <td>Weaponised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{{main|2020 coronavirus outbreak in Europe}}\\n...</td>\n",
       "      <td>--- \\n+++ \\n@@ -33,6 +33,7 @@\\n On '''17 March...</td>\n",
       "      <td>/* Timeline */</td>\n",
       "      <td>Euroserhi</td>\n",
       "      <td>2020-03-18T23:05:13Z</td>\n",
       "      <td>Described change: Added information about new ...</td>\n",
       "      <td>Weaponised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{{main|2020 coronavirus outbreak in Europe}}\\n...</td>\n",
       "      <td>--- \\n+++ \\n@@ -36,7 +36,7 @@\\n \\n Later that ...</td>\n",
       "      <td>A space removed</td>\n",
       "      <td>Ad√ªn√¢i</td>\n",
       "      <td>2020-03-20T03:04:05Z</td>\n",
       "      <td>Change Description: Removed a space in the tex...</td>\n",
       "      <td>Weaponised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{{main|2020 coronavirus outbreak in Europe}}\\n...</td>\n",
       "      <td>--- \\n+++ \\n@@ -28,13 +28,13 @@\\n \\n On '''12 ...</td>\n",
       "      <td>/* Timeline */</td>\n",
       "      <td>Rygor2002</td>\n",
       "      <td>2020-03-20T16:44:22Z</td>\n",
       "      <td>The change made was the correction of the spel...</td>\n",
       "      <td>Weaponised</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     initial_version  \\\n",
       "0  {{main|2020 coronavirus outbreak in Europe}}\\n...   \n",
       "1  {{main|2020 coronavirus outbreak in Europe}}\\n...   \n",
       "2  {{main|2020 coronavirus outbreak in Europe}}\\n...   \n",
       "3  {{main|2020 coronavirus outbreak in Europe}}\\n...   \n",
       "4  {{main|2020 coronavirus outbreak in Europe}}\\n...   \n",
       "\n",
       "                                     changed_version  \\\n",
       "0  --- \\n+++ \\n@@ -26,7 +26,7 @@\\n On 3 March, Uk...   \n",
       "1  --- \\n+++ \\n@@ -17,18 +17,17 @@\\n The [[2019‚Äì2...   \n",
       "2  --- \\n+++ \\n@@ -33,6 +33,7 @@\\n On '''17 March...   \n",
       "3  --- \\n+++ \\n@@ -36,7 +36,7 @@\\n \\n Later that ...   \n",
       "4  --- \\n+++ \\n@@ -28,13 +28,13 @@\\n \\n On '''12 ...   \n",
       "\n",
       "                                             comment           user  \\\n",
       "0                                           cite web  VanHelsing.16   \n",
       "1  /* Timeline */ copyediting - millions of Ukrai...           Boud   \n",
       "2                                     /* Timeline */      Euroserhi   \n",
       "3                                    A space removed         Ad√ªn√¢i   \n",
       "4                                     /* Timeline */      Rygor2002   \n",
       "\n",
       "                   date                                         llm_output  \\\n",
       "0  2020-03-13T14:04:15Z  Change: Replaced a URL reference with a citati...   \n",
       "1  2020-03-16T02:16:56Z  The change made in this revision is the replac...   \n",
       "2  2020-03-18T23:05:13Z  Described change: Added information about new ...   \n",
       "3  2020-03-20T03:04:05Z  Change Description: Removed a space in the tex...   \n",
       "4  2020-03-20T16:44:22Z  The change made was the correction of the spel...   \n",
       "\n",
       "   weaponised  \n",
       "0  Weaponised  \n",
       "1  Weaponised  \n",
       "2  Weaponised  \n",
       "3  Weaponised  \n",
       "4  Weaponised  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_weaponised[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ad577c4-8a3f-49e4-afc9-6f2f932c4828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfs_weaponised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d7fadfea-737d-41e7-8bc5-ede8122a029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def generate_ngrams(text, n=4):\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i+n]) for i in range(len(words) - n + 1)]\n",
    "\n",
    "def check_global(ngrams, dfs):\n",
    "    \"\"\"Search across all weaponised DataFrames for ngram matches in 'changed_version'.\"\"\"\n",
    "    matches = []\n",
    "    for i, df in enumerate(dfs):\n",
    "        if \"changed_version\" not in df.columns:\n",
    "            continue\n",
    "        for ng in ngrams:\n",
    "            found_rows = df[df[\"changed_version\"].astype(str).str.contains(ng, case=False, na=False, regex=False)]\n",
    "            if not found_rows.empty:\n",
    "                matches.append({\n",
    "                    \"df_index\": i,\n",
    "                    \"ngram\": ng,\n",
    "                    \"rows\": found_rows.index.tolist()\n",
    "                })\n",
    "    return matches\n",
    "\n",
    "def check_local(chunk, dfs_named):\n",
    "    \"\"\"Given a text chunk, find which article(s) contain it in 'changed_version'.\"\"\"\n",
    "    for name, df in dfs_named.items():\n",
    "        if \"changed_version\" not in df.columns:\n",
    "            continue\n",
    "        found_rows = df[df[\"changed_version\"].astype(str).str.contains(chunk, case=False, na=False, regex=False)]\n",
    "        if not found_rows.empty:\n",
    "            return name, found_rows\n",
    "    return None, pd.DataFrame()\n",
    "\n",
    "def match_unknown_edits(fg, dfs_weaponised, dfs_named, n=4, limit=None):\n",
    "    \"\"\"\n",
    "    Enhanced version:\n",
    "    - For each edit chunk in fg, generate n-grams.\n",
    "    - Search all weaponised DataFrames for matches.\n",
    "    - Collect all matching rows across articles into a separate DataFrame.\n",
    "    - Fill 'username', 'article', 'date' in fg from the first match only.\n",
    "    \"\"\"\n",
    "    updated_rows = []\n",
    "    all_matches = []\n",
    "    total = len(fg) if limit is None else min(limit, len(fg))\n",
    "\n",
    "    print(total)\n",
    "    for idx, row in tqdm(fg.iterrows(), total=total, desc=\"üîç Matching edits\"):\n",
    "        after_text = row.get(\"aligned_after_chunk\", \"\")\n",
    "        if not isinstance(after_text, str) or not after_text.strip():\n",
    "            continue\n",
    "\n",
    "        ngrams = generate_ngrams(after_text, n)\n",
    "        matches = check_global(ngrams, dfs_weaponised)\n",
    "\n",
    "        if not matches:\n",
    "            continue\n",
    "\n",
    "        detailed_matches = []\n",
    "\n",
    "        for match in matches:\n",
    "            ngram = match[\"ngram\"]\n",
    "            df_index = match[\"df_index\"]\n",
    "            df = dfs_weaponised[df_index]\n",
    "\n",
    "            for row_index in match[\"rows\"]:\n",
    "                article_name, found_rows = check_local(ngram, dfs_named)\n",
    "                if article_name is None or found_rows.empty:\n",
    "                    continue\n",
    "\n",
    "                df_article = dfs_named[article_name]\n",
    "                if row_index not in df_article.index:\n",
    "                    continue\n",
    "\n",
    "                user = df_article.at[row_index, \"user\"] if \"user\" in df_article.columns else None\n",
    "                date = df_article.at[row_index, \"date\"] if \"date\" in df_article.columns else None\n",
    "                comment = df_article.at[row_index, \"comment\"] if \"comment\" in df_article.columns else None\n",
    "                llm_output = df_article.at[row_index, \"llm_output\"] if \"llm_output\" in df_article.columns else None\n",
    "                weaponised_label = df_article.at[row_index, \"weaponised\"] if \"weaponised\" in df_article.columns else None\n",
    "\n",
    "                match_info = {\n",
    "                    # From matched row in dfs_named\n",
    "                    \"article\": article_name,\n",
    "                    \"user\": user,\n",
    "                    \"date\": date,\n",
    "                    \"comment\": comment,\n",
    "                    \"llm_output\": llm_output,\n",
    "                    \"weaponised\": weaponised_label,\n",
    "                    \"ngram\": ngram,\n",
    "                    \"df_index\": df_index,\n",
    "                    \"row_index_matched\": row_index,\n",
    "\n",
    "                    # From current fg row\n",
    "                    \"fg_row_index\": row.get(\"row_index\"),\n",
    "                    \"detected_before\": row.get(\"detected_before\"),\n",
    "                    \"detected_after\": row.get(\"detected_after\"),\n",
    "                    \"clean_before\": row.get(\"clean_before\"),\n",
    "                    \"clean_after\": row.get(\"clean_after\"),\n",
    "                    \"type_of_change_extracted\": row.get(\"type_of_change_extracted\"),\n",
    "                    \"category_extracted_clean\": row.get(\"category_extracted_clean\"),\n",
    "                    \"propaganda_similarity\": row.get(\"propaganda_similarity\"),\n",
    "                    \"category_extracted_propaganda_mapped\": row.get(\"category_extracted_propaganda_mapped\"),\n",
    "                    \"aligned_before_chunk\": row.get(\"aligned_before_chunk\"),\n",
    "                    \"aligned_after_chunk\": row.get(\"aligned_after_chunk\"),\n",
    "                    \"similarity\": row.get(\"similarity\"),\n",
    "                    \"significance_extracted\": row.get(\"significance_extracted\"),\n",
    "                }\n",
    "\n",
    "                detailed_matches.append(match_info)\n",
    "\n",
    "        if detailed_matches:\n",
    "            first = detailed_matches[0]\n",
    "            fg.at[idx, \"username\"] = first[\"user\"]\n",
    "            fg.at[idx, \"article\"] = first[\"article\"]\n",
    "            fg.at[idx, \"date\"] = first[\"date\"]\n",
    "            updated_rows.append(idx)\n",
    "            all_matches.extend(detailed_matches)\n",
    "\n",
    "    print(\"\\n‚úÖ Matching complete.\")\n",
    "    print(f\"Total updated rows in fg: {len(updated_rows)}\")\n",
    "    print(f\"Total collected matches: {len(all_matches)}\")\n",
    "\n",
    "    all_matches_df = pd.DataFrame(all_matches)\n",
    "    return fg, all_matches_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4e025abf-f29f-4755-94ea-9ed61171d965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>detected_before</th>\n",
       "      <th>detected_after</th>\n",
       "      <th>clean_before</th>\n",
       "      <th>clean_after</th>\n",
       "      <th>type_of_change_extracted</th>\n",
       "      <th>category_extracted_clean</th>\n",
       "      <th>propaganda_similarity</th>\n",
       "      <th>category_extracted_propaganda_mapped</th>\n",
       "      <th>aligned_before_chunk</th>\n",
       "      <th>aligned_after_chunk</th>\n",
       "      <th>similarity</th>\n",
       "      <th>significance_extracted</th>\n",
       "      <th>Annot 1</th>\n",
       "      <th>Annot 2</th>\n",
       "      <th>Annot 1 - new</th>\n",
       "      <th>Annot 2 - new</th>\n",
       "      <th>Column 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>A referendum in the largely ethnic Russian [[A...</td>\n",
       "      <td>A referendum in the largely ethnic Russian [[A...</td>\n",
       "      <td>A referendum in the largely ethnic Russian Ukr...</td>\n",
       "      <td>A referendum in the largely ethnic Russian Ukr...</td>\n",
       "      <td>rephrasing and addition of descriptive terms</td>\n",
       "      <td>Terminology Manipulation</td>\n",
       "      <td>0.418396</td>\n",
       "      <td>Obfuscation, intentional vagueness</td>\n",
       "      <td>A referendum in the largely ethnic Russian Ukr...</td>\n",
       "      <td>A referendum in the largely ethnic Russian Ukr...</td>\n",
       "      <td>0.925267</td>\n",
       "      <td>The use of terms like 'bloodless' and 'bloody ...</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>In 1940, after securing the assent of Nazi Ger...</td>\n",
       "      <td>In 1940, after securing the assent of Nazi Ger...</td>\n",
       "      <td>In 1940, after securing the assent of Nazi Ger...</td>\n",
       "      <td>In 1940, after securing the assent of Nazi Ger...</td>\n",
       "      <td>rewording and addition of context</td>\n",
       "      <td>Terminology Manipulation</td>\n",
       "      <td>0.418396</td>\n",
       "      <td>Obfuscation, intentional vagueness</td>\n",
       "      <td>In 1940, after securing the assent of Nazi Ger...</td>\n",
       "      <td>In 1940, after securing the assent of Nazi Ger...</td>\n",
       "      <td>0.981235</td>\n",
       "      <td>The change from 'annex' to 'invade and occupy'...</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>Although local Ukrainians have unsuccesfully a...</td>\n",
       "      <td>Although local Ukrainians have unsuccesfully a...</td>\n",
       "      <td>Although local Ukrainians have unsuccesfully a...</td>\n",
       "      <td>Although local Ukrainians have unsuccesfully a...</td>\n",
       "      <td>addition of a phrase</td>\n",
       "      <td>Terminology Manipulation</td>\n",
       "      <td>0.418396</td>\n",
       "      <td>Obfuscation, intentional vagueness</td>\n",
       "      <td>Although local Ukrainians have unsuccesfully a...</td>\n",
       "      <td>Although local Ukrainians have unsuccesfully a...</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>The addition of 'the policies of Rumanization ...</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>London-based military experts said the soldier...</td>\n",
       "      <td>Western-based military experts said the soldie...</td>\n",
       "      <td>London-based military experts said the soldier...</td>\n",
       "      <td>Western-based military experts said the soldie...</td>\n",
       "      <td>synonym swap</td>\n",
       "      <td>Terminology Manipulation</td>\n",
       "      <td>0.418396</td>\n",
       "      <td>Obfuscation, intentional vagueness</td>\n",
       "      <td>London-based military experts said the soldier...</td>\n",
       "      <td>Western-based military experts said the soldie...</td>\n",
       "      <td>0.927424</td>\n",
       "      <td>This change shifts the attribution of expertis...</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Possibly Incorrect</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>The Nazi administrators of conquered Soviet te...</td>\n",
       "      <td>The Nazi administrators of conquered Soviet te...</td>\n",
       "      <td>The Nazi administrators of conquered Soviet te...</td>\n",
       "      <td>The Nazi administrators of conquered Soviet te...</td>\n",
       "      <td>replacement of terms</td>\n",
       "      <td>Terminology Manipulation</td>\n",
       "      <td>0.418396</td>\n",
       "      <td>Obfuscation, intentional vagueness</td>\n",
       "      <td>The Nazi administrators of conquered Soviet te...</td>\n",
       "      <td>The Nazi administrators of conquered Soviet te...</td>\n",
       "      <td>0.988355</td>\n",
       "      <td>This change shifts the focus from the genocide...</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Possibly Incorrect</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Agree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_index                                    detected_before  \\\n",
       "0          6  A referendum in the largely ethnic Russian [[A...   \n",
       "1         10  In 1940, after securing the assent of Nazi Ger...   \n",
       "2         11  Although local Ukrainians have unsuccesfully a...   \n",
       "3         19  London-based military experts said the soldier...   \n",
       "4         24  The Nazi administrators of conquered Soviet te...   \n",
       "\n",
       "                                      detected_after  \\\n",
       "0  A referendum in the largely ethnic Russian [[A...   \n",
       "1  In 1940, after securing the assent of Nazi Ger...   \n",
       "2  Although local Ukrainians have unsuccesfully a...   \n",
       "3  Western-based military experts said the soldie...   \n",
       "4  The Nazi administrators of conquered Soviet te...   \n",
       "\n",
       "                                        clean_before  \\\n",
       "0  A referendum in the largely ethnic Russian Ukr...   \n",
       "1  In 1940, after securing the assent of Nazi Ger...   \n",
       "2  Although local Ukrainians have unsuccesfully a...   \n",
       "3  London-based military experts said the soldier...   \n",
       "4  The Nazi administrators of conquered Soviet te...   \n",
       "\n",
       "                                         clean_after  \\\n",
       "0  A referendum in the largely ethnic Russian Ukr...   \n",
       "1  In 1940, after securing the assent of Nazi Ger...   \n",
       "2  Although local Ukrainians have unsuccesfully a...   \n",
       "3  Western-based military experts said the soldie...   \n",
       "4  The Nazi administrators of conquered Soviet te...   \n",
       "\n",
       "                       type_of_change_extracted  category_extracted_clean  \\\n",
       "0  rephrasing and addition of descriptive terms  Terminology Manipulation   \n",
       "1             rewording and addition of context  Terminology Manipulation   \n",
       "2                          addition of a phrase  Terminology Manipulation   \n",
       "3                                  synonym swap  Terminology Manipulation   \n",
       "4                          replacement of terms  Terminology Manipulation   \n",
       "\n",
       "   propaganda_similarity category_extracted_propaganda_mapped  \\\n",
       "0               0.418396   Obfuscation, intentional vagueness   \n",
       "1               0.418396   Obfuscation, intentional vagueness   \n",
       "2               0.418396   Obfuscation, intentional vagueness   \n",
       "3               0.418396   Obfuscation, intentional vagueness   \n",
       "4               0.418396   Obfuscation, intentional vagueness   \n",
       "\n",
       "                                aligned_before_chunk  \\\n",
       "0  A referendum in the largely ethnic Russian Ukr...   \n",
       "1  In 1940, after securing the assent of Nazi Ger...   \n",
       "2  Although local Ukrainians have unsuccesfully a...   \n",
       "3  London-based military experts said the soldier...   \n",
       "4  The Nazi administrators of conquered Soviet te...   \n",
       "\n",
       "                                 aligned_after_chunk  similarity  \\\n",
       "0  A referendum in the largely ethnic Russian Ukr...    0.925267   \n",
       "1  In 1940, after securing the assent of Nazi Ger...    0.981235   \n",
       "2  Although local Ukrainians have unsuccesfully a...    0.947917   \n",
       "3  Western-based military experts said the soldie...    0.927424   \n",
       "4  The Nazi administrators of conquered Soviet te...    0.988355   \n",
       "\n",
       "                              significance_extracted  Annot 1  \\\n",
       "0  The use of terms like 'bloodless' and 'bloody ...  Correct   \n",
       "1  The change from 'annex' to 'invade and occupy'...  Correct   \n",
       "2  The addition of 'the policies of Rumanization ...  Correct   \n",
       "3  This change shifts the attribution of expertis...  Correct   \n",
       "4  This change shifts the focus from the genocide...  Correct   \n",
       "\n",
       "              Annot 2 Annot 1 - new Annot 2 - new Column 1  \n",
       "0             Correct       Correct       Correct    Agree  \n",
       "1             Correct       Correct       Correct    Agree  \n",
       "2             Correct       Correct       Correct    Agree  \n",
       "3  Possibly Incorrect       Correct       Correct    Agree  \n",
       "4  Possibly Incorrect       Correct       Correct    Agree  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_chunks = pd.read_excel(\"../datas/raw/best_chunks_semi_automated_annotated_data_repaired.xlsx\")\n",
    "# best_chunks = best_chunks[best_chunks['Annot 1'].fillna('') == 'Correct']\n",
    "# best_chunks = best_chunks[best_chunks['Annot 2'].fillna('') == 'Correct']\n",
    "# best_chunks = best_chunks[best_chunks['Annot 1 - new'].fillna('') == 'Correct']\n",
    "# best_chunks = best_chunks[best_chunks['Annot 2 - new'].fillna('') == 'Correct']\n",
    "\n",
    "best_chunks = best_chunks[\n",
    "    (best_chunks['Annot 1 - new'] == 'Correct') &\n",
    "    (best_chunks['Annot 2 - new'] == 'Correct') &\n",
    "    (best_chunks['Column 1'] == 'Agree')\n",
    "].reset_index(drop=True)\n",
    "\n",
    "best_chunks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d159a6ac-9dc7-44d4-bcdd-957c466973db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(best_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9c0e21d1-1fb1-41a4-91ee-6fb176d764f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîç Matching edits: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 65/65 [1:33:16<00:00, 86.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Matching complete.\n",
      "Total updated rows in fg: 49\n",
      "Total collected matches: 45697\n"
     ]
    }
   ],
   "source": [
    "fg, all_matches_df = match_unknown_edits(best_chunks, dfs_weaponised, dfs_named)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262a49a4-14ac-4f7c-8cbf-43a76d725f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_matches_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd302e11-2b1e-42be-a113-146235045962",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91641407-3afa-4d60-a988-d8e6f9b60ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches_df.iloc[0].clean_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d7ef8d-6147-441c-9dee-9e96ac31bfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches_df.iloc[0].detected_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcce74ac-fb97-4c87-a403-3edc66837f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches_df.iloc[0].detected_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6419b9ef-7c47-4c52-b046-d7849cb30156",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches_df.iloc[0].llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6333c20-d421-4986-84a7-f3841e4d0c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f00565e5-0f7d-4cb9-b703-ceb5d8f59f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches_df.to_csv(\"../datas/interim/matched_edits_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db39d9ff-b139-43ee-a16b-cc2df3f7bfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user = pd.read_csv('../datas/interim/fg_user_known.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11842987-8e55-4636-8536-e278e74bbcfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeedf01b-382d-4fb8-9aa0-80cd97553f14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
