{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8f06c6d5-932c-43e6-a8a0-0290eb61475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root to Python's module search path\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a8027d10-1729-436d-92d7-47cea2eb5779",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_folder = Path(\"../datas/raw/LLM_Results\")\n",
    "dfs = [pd.read_csv(f) for f in csv_folder.glob(\"*.csv\")]\n",
    "dfs_named = {f.stem: pd.read_csv(f) for f in csv_folder.glob(\"*.csv\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "17dfdf1c-00a1-48e2-b3d5-7d46b8c0e549",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_weaponised = [df[df['weaponised'] == 'Weaponised'].reset_index(drop=True) for df in dfs]\n",
    "dfs_weaponised = [df for df in dfs_weaponised if not df.empty]\n",
    "dfs_weaponised_named = {\n",
    "    name: df[df['weaponised'] == 'Weaponised'].reset_index(drop=True)\n",
    "    for name, df in dfs_named.items()\n",
    "    if not df[df['weaponised'] == 'Weaponised'].empty\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d7fadfea-737d-41e7-8bc5-ede8122a029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_global(ngrams, dfs):\n",
    "    \"\"\"\n",
    "    Check across all weaponised DataFrames if any of the ngrams appear\n",
    "    in the 'changed_version' column. Return a list of matches.\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "\n",
    "    for i, df in enumerate(dfs):\n",
    "        if \"changed_version\" not in df.columns:\n",
    "            continue\n",
    "\n",
    "        for ng in ngrams:\n",
    "            found_rows = df[df[\"changed_version\"].astype(str).str.contains(ng, case=False, na=False, regex=False)]\n",
    "            if not found_rows.empty:\n",
    "                matches.append({\n",
    "                    \"df_index\": i,\n",
    "                    \"ngram\": ng,\n",
    "                    \"rows\": found_rows.index.tolist()\n",
    "                })\n",
    "\n",
    "    return matches\n",
    "\n",
    "def check_local(chunk, dfs_named):\n",
    "    \"\"\"\n",
    "    Given a chunk (string) and a dictionary {article_name: df},\n",
    "    find the article name(s) whose 'changed_version' column contains the chunk.\n",
    "    \"\"\"\n",
    "    for name, df in dfs_named.items():\n",
    "        if \"changed_version\" not in df.columns:\n",
    "            continue\n",
    "\n",
    "        found_rows = df[df[\"changed_version\"].astype(str).str.contains(chunk, case=False, na=False, regex=False)]\n",
    "        if not found_rows.empty:\n",
    "            return name, found_rows\n",
    "\n",
    "    return None, pd.DataFrame()\n",
    "\n",
    "def generate_ngrams(text, n=4):\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i+n]) for i in range(len(words)-n+1)]\n",
    "\n",
    "def match_unknown_edits(fg, dfs_weaponised, dfs_named, n=4, limit=None):\n",
    "    \"\"\"\n",
    "    Main pipeline:\n",
    "    - For each unknown edit in fg, generate n-grams.\n",
    "    - Search globally across weaponised DataFrames for matches.\n",
    "    - Identify the most probable article via local check.\n",
    "    - Retrieve the matching user and update fg with article, username, and date.\n",
    "    \"\"\"\n",
    "    updated_rows = []\n",
    "    total = len(fg) if limit is None else min(limit, len(fg))\n",
    "\n",
    "    for idx, row in fg.head(total).iterrows():\n",
    "        after_text = row.get('after_json_text', '')\n",
    "        if not isinstance(after_text, str) or not after_text.strip():\n",
    "            continue\n",
    "\n",
    "        print('-' * 80)\n",
    "        print(f\"Checking edit {idx}/{total}\")\n",
    "\n",
    "        ngrams = generate_ngrams(after_text, n)\n",
    "        matches = check_global(ngrams, dfs_weaponised)\n",
    "\n",
    "        if not matches:\n",
    "            print(\"→ No matches found in any DataFrame.\")\n",
    "            continue\n",
    "\n",
    "        # Heuristic: choose the df_index with the most matches\n",
    "        df_index_counts = {}\n",
    "        for m in matches:\n",
    "            df_index_counts[m[\"df_index\"]] = df_index_counts.get(m[\"df_index\"], 0) + 1\n",
    "        best_df_index = max(df_index_counts, key=df_index_counts.get)\n",
    "        print(f\"→ Most matches found in DataFrame {best_df_index}\")\n",
    "\n",
    "        # Get one representative ngram from this df\n",
    "        representative_ngram = next(m[\"ngram\"] for m in matches if m[\"df_index\"] == best_df_index)\n",
    "\n",
    "        # Try to identify article name via local check\n",
    "        article_name, found_rows = check_local(representative_ngram, dfs_named)\n",
    "        if article_name is None:\n",
    "            print(\"→ Could not identify article name.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"→ Match found in article: {article_name}\")\n",
    "\n",
    "        # Retrieve user info\n",
    "        for i in found_rows.index:\n",
    "            user = dfs_named[article_name].loc[i, \"user\"] if \"user\" in dfs_named[article_name].columns else None\n",
    "            date = dfs_named[article_name].loc[i, \"date\"] if \"date\" in dfs_named[article_name].columns else None\n",
    "\n",
    "            print(f\"   → User: {user}, Date: {date}\")\n",
    "            fg.at[idx, 'username'] = user\n",
    "            fg.at[idx, 'article'] = article_name\n",
    "            fg.at[idx, 'date'] = date\n",
    "            updated_rows.append(idx)\n",
    "            break  # take first match\n",
    "\n",
    "    print(\"\\n✅ Matching complete.\")\n",
    "    print(f\"Total updated rows: {len(updated_rows)}\")\n",
    "\n",
    "    return fg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db39d9ff-b139-43ee-a16b-cc2df3f7bfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = pd.read_csv('../datas/interim/fg_user_known.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADA Env",
   "language": "python",
   "name": "ada"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
